{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/torch_geometric/data/dataset.py:240: UserWarning: The `pre_transform` argument differs from the one used in the pre-processed version of this dataset. If you want to make use of another pre-processing technique, pass `force_reload=True` explicitly to reload the dataset.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from yaml import safe_load\n",
    "from core.data.unimers import UnimersData\n",
    "\n",
    "data_hparams = safe_load(open(\"/remote/gpu04/hummerich/mol-fff/mol-fff/config/unimers_autoencoder.yaml\"))[\n",
    "    \"data_hparams\"\n",
    "]\n",
    "data = UnimersData(UnimersData.hparams_schema.from_dict(data_hparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "\n",
    "\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.utils import unbatch\n",
    "from torch_geometric import nn as gnn\n",
    "\n",
    "from hydrantic.model import Model, ModelHparams\n",
    "from hydrantic.hparams import Hparam\n",
    "\n",
    "from core.models.cross_modality_ae import CrossModalityAE\n",
    "from core.components.set_rff import RFF\n",
    "from core.components.set_attention import SAB\n",
    "from core.utils.masking import pad_sets, unpad_sets\n",
    "from core.utils.graphs import dense_edge_index\n",
    "from core.utils.molecules import get_molecule_from_data\n",
    "from core.utils.sets import length_encoding\n",
    "from core.metrics.molecules import Validity, Components, Uniqueness\n",
    "\n",
    "\n",
    "class PermutationEquivariantLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        output_dim: int,\n",
    "        hidden_dim: int,\n",
    "        heads: int,\n",
    "        mlp_widths: list[int],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.state_update = RFF(2 * hidden_dim, hidden_dim, mlp_widths, activation=\"torch.nn.ELU\")\n",
    "        self.interaction_sab = SAB(input_dim + hidden_dim, hidden_dim, heads)\n",
    "        self.observation = RFF(hidden_dim, output_dim, mlp_widths, activation=\"torch.nn.ELU\")\n",
    "\n",
    "    def forward(self, x: Tensor, s: Tensor, lengths: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        m = self.interaction_sab(torch.concat((s, x), dim=-1), lengths)\n",
    "        x = x + self.observation(m, lengths)\n",
    "        s = self.state_update(torch.concat((s, m), dim=-1), lengths)\n",
    "        return x, s\n",
    "\n",
    "\n",
    "class PermutationEquivariantNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        hidden_dim: int,\n",
    "        heads: int,\n",
    "        mlp_widths: list[int],\n",
    "        num_layers: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [PermutationEquivariantLayer(dim, dim, hidden_dim, heads, mlp_widths) for _ in range(num_layers)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor, s: Tensor, lengths: Tensor) -> Tensor:\n",
    "        for layer in self.layers:\n",
    "            x, s = layer(x, s, lengths)\n",
    "        return x\n",
    "\n",
    "\n",
    "class NodeEmbeddingFMHparams(ModelHparams):\n",
    "    dim: int\n",
    "    hidden_dim: int = Hparam(ge=1)\n",
    "    num_bead_classes: int\n",
    "    mlp_widths: list[int]\n",
    "    heads: int\n",
    "    num_layers: int = Hparam(ge=1)\n",
    "\n",
    "    graph_autoencoder_ckpt: str\n",
    "\n",
    "    latent_distribution: Literal[\"normal\"] = \"normal\"\n",
    "\n",
    "\n",
    "class NodeEmbeddingFM(Model):\n",
    "    hparams_schema = NodeEmbeddingFMHparams\n",
    "    graph_autoencoder: CrossModalityAE\n",
    "\n",
    "    def __init__(self, hparams: NodeEmbeddingFMHparams):\n",
    "        super().__init__(hparams)\n",
    "        self.net = self._configure_network()\n",
    "        self.bead_embedding = nn.Linear(self.hparams.num_bead_classes, self.hparams.hidden_dim)\n",
    "        self.graph_autoencoder = self._configure_graph_autoencoder()\n",
    "\n",
    "    def _configure_network(self) -> nn.Module:\n",
    "        return PermutationEquivariantNet(\n",
    "            self.hparams.dim,\n",
    "            self.hparams.hidden_dim,\n",
    "            self.hparams.heads,\n",
    "            self.hparams.mlp_widths,\n",
    "            self.hparams.num_layers,\n",
    "        )\n",
    "\n",
    "    def forward(self, t: Tensor, x_t: Tensor, lengths: Tensor, c: Tensor | None = None) -> Tensor:\n",
    "        s = self.bead_embedding(c) if c is not None else torch.zeros(x_t.size(0), x_t.size(1), self.hparams.hidden_dim)\n",
    "        s += t\n",
    "        return self.net(x_t, s, lengths)\n",
    "\n",
    "    def compute_metrics(self, batch: Batch, batch_idx):\n",
    "        metrics: dict[str, Tensor] = {}\n",
    "        loss_fn = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x_1, lengths = self.embed(batch)\n",
    "\n",
    "        c = batch.bead.unsqueeze(1).repeat(1, x_1.size(1), 1)\n",
    "\n",
    "        x_0 = torch.randn_like(x_1)\n",
    "\n",
    "        x_1.requires_grad = True\n",
    "        x_0.requires_grad = True\n",
    "        t = torch.rand(x_1.shape[0], 1, 1, device=x_1.device, dtype=x_1.dtype)\n",
    "\n",
    "        x_t = (1 - t) * x_0 + t * x_1\n",
    "        dx_t = x_1 - x_0\n",
    "\n",
    "        metrics[\"loss\"] = loss_fn(self(t, x_t, lengths, c=c), dx_t).sum(dim=-1).mean()\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def step(\n",
    "        self,\n",
    "        x_t: Tensor,\n",
    "        t_start: Tensor,\n",
    "        t_end: Tensor,\n",
    "        lengths: Tensor,\n",
    "        c: Tensor | None = None,\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Integration step between two time points.\n",
    "\n",
    "        :param x_t: position at time t_start.\n",
    "        :param t_start: start time of the integration step.\n",
    "        :param t_end: end time of the integration step.\n",
    "        :return: position at time t_end.\"\"\"\n",
    "\n",
    "        t_start = t_start.view(1, 1).expand(x_t.shape[0], 1, 1)\n",
    "\n",
    "        return x_t + (t_end - t_start) * self(\n",
    "            t_start + (t_end - t_start) / 2,\n",
    "            x_t + self(t_start, x_t, lengths, c=c) * (t_end - t_start) / 2,\n",
    "            lengths,\n",
    "            c=c,\n",
    "        )\n",
    "\n",
    "    def embed(self, batch: Batch) -> tuple[Tensor, Tensor]:\n",
    "        \"\"\"Embeds a batch of graphs as a set of node embeddings.\n",
    "\n",
    "        :param batch: A batch of graphs.\n",
    "        :return: A batch of node embeddings and the corresponding lengths.\"\"\"\n",
    "\n",
    "        h_graph = self.graph_autoencoder.encode(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "        h_list = unbatch(h_graph, batch.batch)\n",
    "        h, lengths = pad_sets(h_list)\n",
    "        return h, lengths\n",
    "\n",
    "    def reconstruct(self, h: Tensor, lengths) -> Batch:\n",
    "        \"\"\"Reconstructs the graph structures from a set of node embeddings.\n",
    "\n",
    "        :param h: A batch of node embeddings.\n",
    "        :param lengths: A batch of lengths.\n",
    "        :return: A batch of graph structures.\"\"\"\n",
    "\n",
    "        batch_code = self.set_to_graph(h, lengths)\n",
    "        x1, edge_attr1 = self.graph_autoencoder.decode(batch_code.x, batch_code.edge_index, batch_code.batch)\n",
    "        batch1 = batch_code.clone()\n",
    "        batch1.x = x1\n",
    "        batch1.edge_attr = edge_attr1\n",
    "        return batch1\n",
    "\n",
    "    def _configure_graph_autoencoder(self) -> CrossModalityAE:\n",
    "        graph_autoencoder = CrossModalityAE.load_from_checkpoint(\n",
    "            self.hparams.graph_autoencoder_ckpt, map_location=self.device\n",
    "        )\n",
    "        graph_autoencoder = graph_autoencoder.eval()\n",
    "        graph_autoencoder = graph_autoencoder.requires_grad_(False)\n",
    "        graph_autoencoder.freeze()\n",
    "        return graph_autoencoder\n",
    "\n",
    "    @property\n",
    "    def num_bond_classes(self) -> int:\n",
    "        \"\"\"Number of bond classes.\"\"\"\n",
    "        num_edge_classes: dict[str, int] = {\n",
    "            \"qm9\": 5,\n",
    "            \"pcqm4m\": 5,\n",
    "            \"zinc\": 4,\n",
    "            \"unimers\": 4,\n",
    "        }\n",
    "        return num_edge_classes[self.graph_autoencoder.hparams.profile]\n",
    "\n",
    "    @property\n",
    "    def num_atom_classes(self) -> int:\n",
    "        \"\"\"Number of atom classes.\"\"\"\n",
    "        num_atom_classes: dict[str, int] = {\n",
    "            \"qm9\": 9,\n",
    "            \"pcqm4m\": 36,\n",
    "            \"zinc\": 28,\n",
    "            \"unimers\": 4,\n",
    "        }\n",
    "        return num_atom_classes[self.graph_autoencoder.hparams.profile]\n",
    "\n",
    "    def graph_to_set(self, batch: Batch) -> tuple[Tensor, Tensor]:\n",
    "        \"\"\"Transforms a batch of graphs to a batch of sets.\n",
    "\n",
    "        :param batch: batch of graphs to transform\n",
    "        :return: batch of sets\"\"\"\n",
    "\n",
    "        x_list = unbatch(batch.x, batch.batch)\n",
    "        x_list, lengths = pad_sets(x_list)\n",
    "        return x_list, lengths\n",
    "\n",
    "    def set_to_graph(self, x: Tensor, lengths: Tensor) -> Batch:\n",
    "        \"\"\"Transforms a batch of sets to a batch of fully connected graphs with empty edge attributes.\n",
    "\n",
    "        :param x: batch of sets to transform\n",
    "        :param lengths: batch of sets lengths\n",
    "        :return: batch of sets\"\"\"\n",
    "\n",
    "        x_list = unpad_sets(x, lengths)\n",
    "        geom_data_list = [\n",
    "            Data(\n",
    "                x=x_list[i],\n",
    "                edge_index=dense_edge_index(lengths[i].item(), x.device),\n",
    "                edge_attr=torch.empty(\n",
    "                    (lengths[i] ** 2 - lengths[i], self.num_bond_classes),\n",
    "                    device=x.device,\n",
    "                ),\n",
    "            )\n",
    "            for i in range(len(x_list))\n",
    "        ]\n",
    "        return Batch.from_data_list(geom_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                      | Params | Mode \n",
      "------------------------------------------------------------------------\n",
      "0 | net               | PermutationEquivariantNet | 57.3 K | train\n",
      "1 | bead_embedding    | Linear                    | 864    | train\n",
      "2 | graph_autoencoder | CrossModalityAE           | 53.7 K | eval \n",
      "------------------------------------------------------------------------\n",
      "58.1 K    Trainable params\n",
      "53.7 K    Non-trainable params\n",
      "111 K     Total params\n",
      "0.447     Total estimated model params size (MB)\n",
      "103       Modules in train mode\n",
      "174       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  24%|██▎       | 274/1156 [00:05<00:17, 51.86it/s, training/loss=9.050] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1025\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1025\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py:250\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:190\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:268\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:167\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 167\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py:1306\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \n\u001b[1;32m   1305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1306\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py:153\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:238\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision.py:122\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    211\u001b[0m beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 213\u001b[0m has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m adam(\n\u001b[1;32m    224\u001b[0m     params_with_grad,\n\u001b[1;32m    225\u001b[0m     grads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m     found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    244\u001b[0m )\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/torch/optim/adam.py:127\u001b[0m, in \u001b[0;36mAdam._init_group\u001b[0;34m(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     has_complex \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     params_with_grad\u001b[38;5;241m.\u001b[39mappend(p)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m NodeEmbeddingFM(\n\u001b[1;32m      2\u001b[0m     NodeEmbeddingFMHparams(\n\u001b[1;32m      3\u001b[0m         dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/hydrantic/src/hydrantic/model/model.py:188\u001b[0m, in \u001b[0;36mModel.fit_fast\u001b[0;34m(self, train_loader, val_loader, n_epochs, lr, accelerator, precision, verbose)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m OptimizerHparams(module_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.optim.Adam\u001b[39m\u001b[38;5;124m\"\u001b[39m, kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: lr})\n\u001b[1;32m    185\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    186\u001b[0m     logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, accelerator\u001b[38;5;241m=\u001b[39maccelerator, precision\u001b[38;5;241m=\u001b[39mprecision, max_epochs\u001b[38;5;241m=\u001b[39mn_epochs, enable_progress_bar\u001b[38;5;241m=\u001b[39mverbose\n\u001b[1;32m    187\u001b[0m )\n\u001b[0;32m--> 188\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/remote/gpu04/hummerich/mol-fff/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "model = NodeEmbeddingFM(\n",
    "    NodeEmbeddingFMHparams(\n",
    "        dim=10,\n",
    "        hidden_dim=32,\n",
    "        mlp_widths=[64],\n",
    "        num_bead_classes=26,\n",
    "        heads=2,\n",
    "        num_layers=4,\n",
    "        graph_autoencoder_ckpt=\"/remote/gpu04/hummerich/mol-fff/mol-fff/lightning_logs/Selected Models/CrossModalityAE.ckpt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "model = model.fit_fast(data.train_loader, n_epochs=100, accelerator=\"gpu\", lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(data.train_loader))\n",
    "batch_size = batch.num_graphs\n",
    "with torch.no_grad():\n",
    "    x = torch.randn(batch_size, 9, 10)\n",
    "    lengths = torch.ones(batch_size, dtype=torch.long) * 9\n",
    "\n",
    "    n_steps = 101\n",
    "    time_steps = torch.linspace(0, 2.0, n_steps + 1)\n",
    "    traj = [x]\n",
    "    for i in range(n_steps):\n",
    "        x = model.step(x_t=x, t_start=time_steps[i], t_end=time_steps[i + 1], lengths=lengths, c=batch.bead.unsqueeze(1).repeat(1, 9, 1))\n",
    "        if i % 20 == 0:\n",
    "            traj.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:55:05] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<rdkit.Chem.rdchem.RWMol at 0x7feaf4bad850>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = traj[-1]\n",
    "\n",
    "batch = model.reconstruct(h, lengths)\n",
    "\n",
    "mols = [get_molecule_from_data(batch[i].x, batch[i].edge_index, batch[i].edge_attr) for i in range(batch.num_graphs)]\n",
    "mols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
